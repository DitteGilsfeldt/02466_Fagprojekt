{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logbook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning goals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At kunne træne AI modeller på data\n",
    "\n",
    "At kunne forstå datasæt\n",
    "\n",
    "Være bekendt med at kode machine learning modeller\n",
    "\n",
    "At kunne bruge forskellige machine learning modeller\n",
    "\n",
    "At kunne evaluere modellernes performance\n",
    "\n",
    "At bruge statistiske tests til evaluering\n",
    "\n",
    "At kunne bruge modellerne til at bestemme hvilke patienter, der er i høj eller lav risiko\n",
    "\n",
    "At kunne bruge f.eks. gaussian modeller til at forudsige manglende punkter (manglende huller i modellen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Template"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Questions\n",
    "    * Questions here, and who to ask\n",
    "* Reading, who and what\n",
    "    * What was read?\n",
    "* Implementation, who and what\n",
    "    * What was implemented and worked on\n",
    "* Results, who and what\n",
    "    * Results of these implementations.\n",
    "    * Do we need to reevaluate the results next time\n",
    "* Decisions, who and what, what do you do alone, what do you do together\n",
    "    * What decisions were made?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project meetings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 07/02/2024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Questions\n",
    "    * When do we get access to the project dataset? Ask supervisor\n",
    "* Reading, who and what\n",
    "    * No material was read today.\n",
    "* Implementation, who and what\n",
    "    * A colaboration-contract has been made containing the aproach and what is expected of eachother.\n",
    "    * We have formulated some questions we want to ask the supervisor for the next meeting.\n",
    "* Results, who and what\n",
    "    * We have finished the colaboration - contract which is a part of the assignment the 28/2.\n",
    "* Decisions, who and what, what do you do alone, what do you do together\n",
    "    * A meeting has been set up with the supervisors next Tuesday 13/2 16:00. This will be a virtual meeting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 21/02/24"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vi (Ditte, Lucia, Viktor) mødtes til vejleder mødet, hvor vi efterfølgende, opdaterede vores gruppemedlem der ikke hørte starten af vejledermødet grundet forsinkelse på en halv time (Muneer). \n",
    "Dertil arbejde vi på at få udarbejdet en projekt beskrivelse, samt læse de links vi har fået givet omkring EuroSCORE. \n",
    "\n",
    "Vi havde en 5-6 forskingsspørgsmål, vi lige ville lade ligge til efter forelsæningen, og lige få klart syn på hvad vi ville i fagprojektet. \n",
    "Efter forelæsnignen havde vi møde med vores \"søster-gruppe\" hvor vi brainstromede på forskingsspørgsmål, dette møde deltager Ditte, Lucia og Viktor.\n",
    "\n",
    "**Brainstorm forskningsspørgsmål** \\\n",
    "<img src= \"img/2024-02-28-14-13-25.png\" style=\"width:30rem;\">\n",
    "\n",
    "Efter vi havde brainstormet, kiggede vi på vores forskingsspørgsmål og næsten færdig gjort vores udkast til projekt beskrivelsen. \n",
    "Projektbeskrivelsen, skrives primært at Ditte, Lucia og Viktor, da Muneer ikke havde sin computer med, og ikke har responderet på meddelser på Discord ang. ændringer i projekt beskrivelsen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 27/02/24"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "kl 10.54 har Ditte Lucia og Viktor godkendt nyt vejleder møde, efter samtale på discord, hvor Muneer ikke har deltaget i samtale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 28/02/24"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ditte, Lucia og Viktor mødes efter forelæsningen og skriver projekt beskrivelsen færdig, med de rettelser der er kommet fra vejleder. \n",
    "\n",
    "Dertil udarbejdes der en mail til Muneer, ang. gruppe samarbejdet. \n",
    "\n",
    "Der undersøges litteratur til vores projekt. \n",
    "\n",
    "Ingen besked fra Muneer om fraværelse.\n",
    "\n",
    "Projektbeskrivelse, Gantt Chart, Samarbejdsaftale, Project Canvas og Læringsmål afleveret."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Forløbige artikler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://findit.dtu.dk/en/catalog/652c8a0f2fa76a1b70c0f344\n",
    "- https://findit.dtu.dk/en/catalog/64bf66db76bd98312b7d8cd7\n",
    "- https://findit.dtu.dk/en/catalog/6420dfb03a65a13c29450683\n",
    "- https://findit.dtu.dk/en/catalog/5c47be8bd9001d019d32f1db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Mail sendt til Muneer:**\\\n",
    "Hej.\n",
    "Vi oplever at der er nogle problemer og mangler i forhold til vores samarbejde. \n",
    "\n",
    "Vi synes, at det er svært at have et samarbejde om projektet, når du kommer for sent til møderne, ikke dukker op til det aftalte, og ydermere ikke kommer og har en computer med til at kunne bidrage med at skrive på projekt beskrivelsen. \n",
    "\n",
    "Dertil ønsker vi at der kommer kommunikation, som også har været manglende på det seneste. Jeg referer til vores sammenarbejdskontrakt, hvor vi har skrevet under på at man giver besked, når man ikke kommer. Dette hører vi intet om, idet svar og reaktioner på vores discord server er manglende.\n",
    "\n",
    "I flere tilfælde har vi meddelt opdateringer i forhold til, hvor langt vi er med det nuværende arbejde, hvilke tanker vi har gjort os for fremtidige opgaver samt, hvad lægerne har meddelt over teams. Siden vi ikke hører noget fra din side, er vi usikre på, i hvor stor grad du er up-to-date med vores nuværende projekt status. Yderligere, ved vi heller ikke om du har sent en underskrevet kontrakt til lægerne, hvilket et krævet for at kunne bruge computeren, og om du er klar over, at en nyt møde finder sted fredag med en hovedansvarlig fra hospitalets IT-afdeling.\n",
    "\n",
    "Dette gør, at vi har nogle krav til dig, som du skal have bevist inden vores \"midsvejsaflevering\" om 3 uger. Er disse ting ikke blevet bedre, må vi desværre meddele at du ikke kan være en del af vores gruppe derefter. \n",
    "\n",
    "Hold øje med Discord og svar.\n",
    "Være der til, det vi aftaler (også selvom man har travlt, for det har vi alle) .\n",
    "Det forventes 9 timer om ugen og dette har vi ikke krævet over.\n",
    "Hold øje med teams og discord og svar på tingene (så det er tydeligt for os, at du har set beskederne og er opdateret).\n",
    "Medbringe computer hver gang.\n",
    "\n",
    "Mvh \n",
    "Ditte, Lucia og Viktor\n",
    "\n",
    "28/02/24 kl 15:40"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Muneer bliver smidt ud af gruppe ved samtale med Morten Mørup, da han ikke har svaret i 2,5 uge. Hverken på Discord eller mail. \\\n",
    "Muneer bliver fjernet fra Discord og git. Samme aften kontakter Muneer grupper, med besked hvad er der sket med vores discord gruppe. \\\n",
    "Vi (Ditte, Lucia og Viktor) får at vide af Morten Mørup, at da han nu har svare skal vi stadig give ham en chance og derved skrive til ham. \\\n",
    "\n",
    "**Mail koorspondance med Muneer:**\\\n",
    "06/03/24 kl. 19:50\\\n",
    "\n",
    "Hej,\\\n",
    "Jeg bliver nødt til at indrømme at jeg først ser denne mail nu. Jeg har simpelthen haft en dårlig periode i den sidste måned grundet personlige årsager, der har forårsaget massere af fravær fysisk og skriftligt på DTU, og jeg er ikke selv tilfreds med mit bidrag og ustabilitet.  Jeg er virkelig ked af jeg hvis jeg ikke kan være med fremover for jeg har mange gode ideer og tænker tit på projektet (har bare ikke haft mulighed på at arbejde på det tekniske grundet vi manglede data.)  Jeg er tilbage på fødderne nu, og jeg håber i kan give mig en chance til, hvor jeg så lover jeg overholder vores aftaler mht. samarbejdskontrakten, for det er virkelig et projekt jeg vil arbejde på og have det bedste ud af.\n",
    "\n",
    "Venlig hilsen,\\\n",
    "Muneer\\\n",
    "\n",
    "\n",
    "07/03/24 \\\n",
    "kl 08:36\\\n",
    "Kære Ditte, Lucia og Victor,\n",
    " \n",
    "Kan se Muneer igår har svaret på jeres besked, inden jeg i dag ville skrive ud til ham og jer om gruppesamarbejdet.\\\n",
    " \n",
    "Jeg synes vi skal holde fast i planen, vi aftalte oprindeligt. Dvs. give Muneer opgaver til midtvejsafleveringen, og hvis der ikke leveres på disse som aftalt og samarbejdet med hans indsats stadig ikke er tilfredsstillende, må skridtet tages videre til at han ikke kan være en del af jeres gruppe.\n",
    " \n",
    "Vil I skrive til Muneer og sikre han har klare opgaver at levere på til jeres samarbejde, som aftalt.\n",
    " \n",
    "Bedste hilsener\\\n",
    "Morten\n",
    "\n",
    "\n",
    "kl 08:40\\\n",
    "Hej Morten.\\\n",
    "Vi svarer Muneer på hans mail og holder fast i planen. \n",
    "\n",
    "Mvh\\\n",
    "Ditte Gilsfeldt \\\n",
    "Studie nr: s210666\n",
    "\n",
    "\n",
    "kl 08:52\\\n",
    "Hej Muneer. \\\n",
    "Vi giver dig en chance til i gruppen, men må indrømme at selvom man personlig har det svært, så er man også nødt til at være ansvarlig og få kommunikeret til sin gruppe. At der intet er hørt fra dig i 2 en halv uge, det er ikke okay. Vi kan jo lidt se du følger med på discord siden du samme dag opdager at du egentlig er ude af gruppen, samt flere gange er online, til at vi meget har undret os over den manglende kommunikation. \n",
    "\n",
    "Vi vælger dog stadig med vores ret, at hvis tingene ikke bliver bedre inden midtvejsevalueringen, så kan du ikke være en del af gruppen. \n",
    "\n",
    "Det gælder at du overholder følgende: \\\n",
    "Får underskrevet kontrakten med Rigshospitalet, før dette kan du ikke bruge computeren. \\\n",
    "Kommunikere til os og vejleder\\\n",
    "Kommer til det aftalte til tiden og også med computer. \n",
    "\n",
    "Dertil har vi andre heller ikke kunne arbejde på dataen da vi først får computeren i morgen, men det betyder ikke at der ikke har været ting der skulle laves. \n",
    "\n",
    "Mvh\\\n",
    "Ditte Gilsfeldt \\\n",
    "Studie nr: s210666\n",
    "\n",
    "\n",
    "kl 14:20\\\n",
    "Hej,\\\n",
    "Kan du hjælpe mig med den kontrakt der skal sendes til Rigshospitalet? Hvor er den og hvordan skal den sendes?  Tak på forhånd.\n",
    "\n",
    "Venlig hilsen,\\\n",
    "Muneer\n",
    "\n",
    "kl 17:11\\\n",
    "Send mig lige din oplysninger til git og discord. Så tilføjer jeg dig igen. Og så ligger den der inde.\n",
    "\n",
    "Mvh\\\n",
    "Ditte Gilsfeldt\\\n",
    "Studie nr: s210666\n",
    "\n",
    "\n",
    "kl 17:55\\\n",
    "Git: muneer-kayali\\\n",
    "Discord: muneerkayali\n",
    "\n",
    "Mvh,\\\n",
    "Muneer\n",
    "\n",
    "kl 20.07\\\n",
    "Prøv lige at tjek om du har adgang nu. Ellers gør jeg det lige i morgen på computeren\n",
    "\n",
    "Mvh\\\n",
    "Ditte Gilsfeldt\\\n",
    "Studie nr: s210666\n",
    "\n",
    "\n",
    "08/03/24 \\\n",
    "kl 09.08\n",
    "\n",
    "Hej Muneer.\\\n",
    "Du burde have adgang når du godkender invitationerne.\n",
    "\n",
    "Mvh\\\n",
    "Ditte Gilsfeldt \\\n",
    "Studie nr: s210666\n",
    "\n",
    "kl 14.10\\\n",
    "Hej, har stadig ikke adgang.\n",
    "\n",
    "Mvh,\\\n",
    "Muneer Kayali\n",
    "\n",
    "kl 15:27\\\n",
    "Har du fået invitationen? \n",
    "\n",
    "Mvh\n",
    "Ditte Gilsfeldt \n",
    "Studie nr: s210666\n",
    "\n",
    "\n",
    "Dertil kommer der ikke flere mails, og Ditte har sendt utallige invitationer til Discord gruppen samt venne anmodning der ikke bliver svaret. \n",
    "Ditte kontakter Muneer på Messenger:\n",
    "\n",
    "\n",
    "10/03/24\\\n",
    "15:28\\\n",
    "Hej Muneer. Jeg har forsøgt i 2 dage at få dig ind i discord gruppen. Det er svært at få dig med i tingene når du kun svarer 1 gang på to timer. Forventer ikke du svarer hele tiden, men hvis du vil ind i discord gruppen, er du nødt til at kommunikere lidt mere med mig, så det kan lykkes. \\\n",
    "Hilsen Ditte\n",
    "\n",
    "Hvor Muneer svarer at han beklager men at han stadig ikke er med i gruppen på discord og at jeg kan sende ham en invitation, dertil svarer Ditte at der er sendt mange link, men at det ikke er muligt før han godkender venneanmodning og hertil kommer det op og kører. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13/03/2024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ditte, Muneer og Viktor mødtes kl 10:00. Lucia er ikke til stede da hun er på ferie.\n",
    "\n",
    "Idag blev der skrevet på raporten,  da midtvejsafleveringen snart skal afleveres. Der blev kigget på flere artikler for at få en bedre forståelse af hvordan mortality kan forudsiges ved brug af AI. Der blev også undersøgt hvilke muligheder for syntetisk data, vi har til rådighed. \n",
    "\n",
    "potentielt library til syntetisk data: https://github.com/sdv-dev/SDV\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 06/06/2024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lucia, Ditte og Viktor er tilstede for at starte med projektet. \n",
    "Intet hørt fra Muneer, og ingen resons på discord. \n",
    "\n",
    "I dag, har vi startede med at kigge videre med at sortere dataen, samt kigge på om vi kan få syntetisk data op og kører. \n",
    "\n",
    "Dertil har vi kun haft mulighed for at arbejde på en computer (rigshospitalets computer), da vi ikke kan flytte dateen fra computeren. \n",
    "Detter har gjort at vi sammen har kigget på det, men dertil er der også blevet kigget på det feedback der er blevet givet, som er ved at blive rettet til i vores rapport. \n",
    "\n",
    "Det er blevet aftalt at mødes med \"søster\" gruppen, for at spare med hianden, på mandag kl 12. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11/06/24"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kl 12:23\n",
    "\n",
    "**User**\n",
    "Can you help me to provide a code/function/class, which can take true and predictive labels from a classifications models. The function should give the relevant statistic test and plot, to validate and analysis the performance?\n",
    "\n",
    "\n",
    "**Chat**\n",
    "Certainly! Below is a Python class that can take true and predicted labels from classification models and provide relevant statistical tests and plots for performance analysis.\n",
    "\n",
    "**Code Implementation**\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, auc\n",
    "from scipy import stats\n",
    "\n",
    "class ClassificationPerformance:\n",
    "    def __init__(self, true_labels, predicted_labels):\n",
    "        self.true_labels = true_labels\n",
    "        self.predicted_labels = predicted_labels\n",
    "        self.conf_matrix = confusion_matrix(self.true_labels, self.predicted_labels)\n",
    "        self.class_report = classification_report(self.true_labels, self.predicted_labels, output_dict=True)\n",
    "        \n",
    "    def plot_confusion_matrix(self):\n",
    "        plt.figure(figsize=(10, 7))\n",
    "        sns.heatmap(self.conf_matrix, annot=True, fmt='d', cmap='Blues')\n",
    "        plt.xlabel('Predicted Labels')\n",
    "        plt.ylabel('True Labels')\n",
    "        plt.title('Confusion Matrix')\n",
    "        plt.show()\n",
    "    \n",
    "    def classification_report_df(self):\n",
    "        report_df = pd.DataFrame(self.class_report).transpose()\n",
    "        return report_df\n",
    "\n",
    "    def plot_roc_curve(self):\n",
    "        fpr, tpr, _ = roc_curve(self.true_labels, self.predicted_labels)\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        \n",
    "        plt.figure(figsize=(10, 7))\n",
    "        plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
    "        plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "        plt.xlim([0.0, 1.0])\n",
    "        plt.ylim([0.0, 1.05])\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        plt.show()\n",
    "    \n",
    "    def chi_square_test(self):\n",
    "        chi2, p, dof, ex = stats.chi2_contingency(self.conf_matrix)\n",
    "        return {'chi2': chi2, 'p_value': p, 'dof': dof, 'expected': ex}\n",
    "\n",
    "    def plot_feature_importance(self, model, feature_names):\n",
    "        if hasattr(model, 'feature_importances_'):\n",
    "            feature_importance = model.feature_importances_\n",
    "            sorted_idx = np.argsort(feature_importance)\n",
    "            plt.figure(figsize=(10, 7))\n",
    "            plt.barh(range(len(sorted_idx)), feature_importance[sorted_idx], align='center')\n",
    "            plt.yticks(range(len(sorted_idx)), np.array(feature_names)[sorted_idx])\n",
    "            plt.xlabel('Feature Importance')\n",
    "            plt.title('Feature Importance')\n",
    "            plt.show()\n",
    "        else:\n",
    "            print(\"Model does not have feature_importances_ attribute.\")\n",
    "\n",
    "# Example usage\n",
    "# true_labels = [actual labels]\n",
    "# predicted_labels = [predicted labels]\n",
    "# model = [your trained model]\n",
    "# feature_names = [list of feature names]\n",
    "\n",
    "# perf = ClassificationPerformance(true_labels, predicted_labels)\n",
    "# perf.plot_confusion_matrix()\n",
    "# print(perf.classification_report_df())\n",
    "# perf.plot_roc_curve()\n",
    "# print(perf.chi_square_test())\n",
    "# perf.plot_feature_importance(model, feature_names)\n",
    "```\n",
    "\n",
    "**Explanation**\n",
    "1. **Initialization**: The class is initialized with true and predicted labels.\n",
    "2. **Confusion Matrix Plot**: The `plot_confusion_matrix` method visualizes the confusion matrix using a heatmap.\n",
    "3. **Classification Report**: The `classification_report_df` method provides a detailed classification report in a DataFrame format.\n",
    "4. **ROC Curve Plot**: The `plot_roc_curve` method plots the ROC curve and calculates the AUC.\n",
    "5. **Chi-Square Test**: The `chi_square_test` method performs a chi-square test on the confusion matrix and returns the test statistics.\n",
    "6. **Feature Importance Plot**: The `plot_feature_importance` method plots the feature importances from the model, if available.\n",
    "\n",
    "This class provides a comprehensive way to validate and analyze the performance of classification models. You can extend this class to include more statistical tests and plots as per your requirements.\n",
    "\n",
    "\n",
    "**User**\\\n",
    "Can you provide me a synthetic dataset, so I can run the code? \n",
    "\n",
    "**Chat**\\\n",
    "Certainly! Here's an example of generating a synthetic dataset using `sklearn` and then running the provided code to evaluate a classification model. We'll use a synthetic dataset created using `make_classification` from `sklearn.datasets`.\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, auc\n",
    "from scipy import stats\n",
    "\n",
    "class ClassificationPerformance:\n",
    "    def __init__(self, true_labels, predicted_labels):\n",
    "        self.true_labels = true_labels\n",
    "        self.predicted_labels = predicted_labels\n",
    "        self.conf_matrix = confusion_matrix(self.true_labels, self.predicted_labels)\n",
    "        self.class_report = classification_report(self.true_labels, self.predicted_labels, output_dict=True)\n",
    "        \n",
    "    def plot_confusion_matrix(self):\n",
    "        plt.figure(figsize=(10, 7))\n",
    "        sns.heatmap(self.conf_matrix, annot=True, fmt='d', cmap='Blues')\n",
    "        plt.xlabel('Predicted Labels')\n",
    "        plt.ylabel('True Labels')\n",
    "        plt.title('Confusion Matrix')\n",
    "        plt.show()\n",
    "    \n",
    "    def classification_report_df(self):\n",
    "        report_df = pd.DataFrame(self.class_report).transpose()\n",
    "        return report_df\n",
    "\n",
    "    def plot_roc_curve(self):\n",
    "        fpr, tpr, _ = roc_curve(self.true_labels, self.predicted_labels)\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        \n",
    "        plt.figure(figsize=(10, 7))\n",
    "        plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
    "        plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "        plt.xlim([0.0, 1.0])\n",
    "        plt.ylim([0.0, 1.05])\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        plt.show()\n",
    "    \n",
    "    def chi_square_test(self):\n",
    "        chi2, p, dof, ex = stats.chi2_contingency(self.conf_matrix)\n",
    "        return {'chi2': chi2, 'p_value': p, 'dof': dof, 'expected': ex}\n",
    "\n",
    "    def plot_feature_importance(self, model, feature_names):\n",
    "        if hasattr(model, 'feature_importances_'):\n",
    "            feature_importance = model.feature_importances_\n",
    "            sorted_idx = np.argsort(feature_importance)\n",
    "            plt.figure(figsize=(10, 7))\n",
    "            plt.barh(range(len(sorted_idx)), feature_importance[sorted_idx], align='center')\n",
    "            plt.yticks(range(len(sorted_idx)), np.array(feature_names)[sorted_idx])\n",
    "            plt.xlabel('Feature Importance')\n",
    "            plt.title('Feature Importance')\n",
    "            plt.show()\n",
    "        else:\n",
    "            print(\"Model does not have feature_importances_ attribute.\")\n",
    "\n",
    "# Generate synthetic dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=20, n_informative=2, n_redundant=10, random_state=42)\n",
    "\n",
    "# Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Train a RandomForestClassifier\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict the labels\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the performance\n",
    "perf = ClassificationPerformance(y_test, y_pred)\n",
    "perf.plot_confusion_matrix()\n",
    "print(perf.classification_report_df())\n",
    "perf.plot_roc_curve()\n",
    "print(perf.chi_square_test())\n",
    "perf.plot_feature_importance(model, [f'feature_{i}' for i in range(X.shape[1])])\n",
    "```\n",
    "\n",
    "**Explanation**\n",
    "1. **Synthetic Dataset**: We use `make_classification` to generate a synthetic dataset with 1000 samples and 20 features.\n",
    "2. **Train-Test Split**: We split the dataset into training and testing sets.\n",
    "3. **Model Training**: We train a `RandomForestClassifier` on the training data.\n",
    "4. **Prediction**: We predict the labels on the test set.\n",
    "5. **Performance Evaluation**: We use the `ClassificationPerformance` class to plot the confusion matrix, classification report, ROC curve, perform a chi-square test, and plot feature importance.\n",
    "\n",
    "You can run this code in your local environment to see the output and validate the performance of the classification model on the synthetic dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kl 12:40\n",
    "\n",
    "**User**\\\n",
    "Do you know how I can make a chi squared test. I give you a text of our data description. \n",
    "\n",
    "\\chapter{Data description}\n",
    "The data used in this project is collected from 8000 patients over five years, who have undergone cardiac surgery at Rigshospitalet. The Cardiac patient data journey has a Preoperative section such as; \"sex, age, medical- and surgical history, etc.\", Perioperative as; \"blood pressure, heart rate, pressure, etc.\", ICU as; \"blood pressure, heart rate, dialysis, etc.\", and Ward as; \"blood pressure, heart rate, medication\" from appendix \\ref{fig: cardiac}. \n",
    "\n",
    "There will be a restriction when working with the data, due to the GDPR rules, thus, the data can only be used on one specific device when training and creating the machine learning models. This also means that all personal information has been anonymized, removing information like CPR numbers. \n",
    "\n",
    "Each measurement and test result is linked to a specific identification number on the form \"ID 1\" in all data files, assuring the tracking of correlation between the samples. None of the observations is specifically labeled as preoperative, perioperative, or postoperative in practice. Measurements like blood pressure are often sampled once under all three categories. Instead, each observation has, along with the ID, a date and time that describes when each observation was noted. In addition to this, the data is structured in multiple tables, which contain duplicate observations making the data very messy. Meanwhile, it is still possible to keep track of when in the surgery process of a patient the observations are made. For a general understanding of the dataset, the following categories have been made:\n",
    "\n",
    "\\section{Profile}\n",
    "The profile describes information about the patient, that is already known before the process of operation begins. The variables documented are:\n",
    "\n",
    "\\begin{table}[H]\n",
    "\\centering\n",
    "\\begin{tabular}{lllll}\n",
    "\\hline\n",
    "    \\textbf{Profile variables}\\\\\n",
    "    \\hline\n",
    "    Biological gender & Male or Female\\\\\n",
    "    Age & Years\\\\\n",
    "    Diagnosis & Name and SKS \\\\\n",
    "    Alcohol & Drinks per week \\\\\n",
    "    Smoking & Frequency and previous history \\\\\n",
    "    \\hline\n",
    "\\end{tabular}\n",
    "\\caption{Profile variables}\n",
    "\\label{table: Profile variables}\n",
    "\\end{table}\n",
    "\n",
    "\\section{Measurements}\n",
    "This section of the data describes all the information that is collected during the patient's hospital duration. These data contain the most information about why and what future complications the patients will experience. In other words, these data will most likely make up the majority of the predicting variables.  \n",
    "\n",
    "\\begin{table}[H]\n",
    "\\centering\n",
    "\\begin{tabular}{lllll}\n",
    "\\hline\n",
    "    \\textbf{Measurement variables}\\\\\n",
    "    \\hline\n",
    "    Blood pressure & Millimetres Mercury(mmHg)\\\\\n",
    "    Mean Arterial Pressure& mmHg \\\\\n",
    "    Invasive Arterial blood pressure & mmHg \\\\\n",
    "    Central venous pressure & mmHg \\\\\n",
    "    Pulmonary Artery Pressure & mmHg\\\\\n",
    "    Oxygen saturation in the blood & Percentage\\\\\n",
    "    respiratory rate & Breaths per minute\\\\\n",
    "    Blood and body temperature & Celsius\\\\\n",
    "    Pulse & Beats per minute\\\\\n",
    "    Weight & in Kilograms, measured several times over the process\\\\\n",
    "    Urine & Millilitres\\\\\n",
    "    Laboratory test results & Very broad, but most important is liver health and infections\\\\\n",
    "    Medicine administered & Both name and amount\\\\\n",
    "    EKG results & Several measurements\\\\\n",
    "    echocardiography & Several measurements\\\\\n",
    "    Coronary angiography & Examination of Coronary arteries\\\\\n",
    "    Spirometer test & Ventilation and general health of the lungs\\\\\n",
    "    Other operations performed & A week after the cardiac surgery\\\\\n",
    "    Total incretion & Food, liquid and IV drop, etc.\\\\\n",
    "    Total excretion & Defecation, urine, vomit, bloodloss, etc.\\\\\n",
    "    Ventilator data & Duration of the assisted breathing and settings\\\\\n",
    "    Duration of anesthesia & Describes the duration of cardiac surgery\\\\\n",
    "    anaesthesia data under the operation & Several measurements\\\\\n",
    "    Blood loss during operation & milliliters and cause of bloodloss\\\\\n",
    "    CV bypass and closing of aorta & Duration of the manoeuvre\\\\\n",
    "    \\hline\n",
    "\\end{tabular}\n",
    "\\caption{Measurement variables}\n",
    "\\label{table: Measurement variables}\n",
    "\\end{table}\n",
    "\n",
    "The most important variables to understand from the dataset would be the CV bypass and closing of the aorta, which is how the blood is kept circulating through the body during the operation. The duration of this can often describe how successful the operation was and how much the patient will bleed during and after the operation, which is a key factor in recovery time. \n",
    "\n",
    "\\section{Admission process and follow up}\n",
    "The Admission process describes how long each patient spends in the different locations. This is documented by specifying the location, for example, \"Thorax intensive\" and also the start of admission and end of admission. Sometimes a patient is transferred from one ICU to another for logistical reasons but as the care in the different ICUs is the same this can be ignored. The duration spent in the ICU will be one of the main target variables \n",
    "\n",
    "The follow-up information with the patients is also documented. This includes variables such as if death has occurred within a year and if so when. This is a very important variable for describing the overall success of the operation.    \n",
    "\n",
    "\n",
    "**Chat**\\\n",
    "To perform a chi-square test using the provided data, we first need to create a synthetic dataset that captures the key elements described. This includes creating variables for the profile section, measurements during the hospital stay, and the admission process and follow-up. For simplicity, we'll generate some synthetic data for a subset of these variables and demonstrate how to perform a chi-square test.\n",
    "\n",
    "Here’s how you can do this in Python:\n",
    "\n",
    "### Step 1: Generate Synthetic Data\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# Set a seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Generate synthetic data for 8000 patients\n",
    "n_patients = 8000\n",
    "\n",
    "# Profile variables\n",
    "gender = np.random.choice(['Male', 'Female'], size=n_patients)\n",
    "age = np.random.randint(18, 90, size=n_patients)\n",
    "diagnosis = np.random.choice(['Diagnosis A', 'Diagnosis B', 'Diagnosis C'], size=n_patients)\n",
    "alcohol = np.random.randint(0, 20, size=n_patients)  # drinks per week\n",
    "smoking = np.random.choice(['Non-smoker', 'Former smoker', 'Current smoker'], size=n_patients)\n",
    "\n",
    "# Measurements variables\n",
    "blood_pressure = np.random.randint(90, 180, size=n_patients)\n",
    "mean_arterial_pressure = np.random.randint(70, 110, size=n_patients)\n",
    "pulse = np.random.randint(50, 120, size=n_patients)\n",
    "oxygen_saturation = np.random.randint(85, 100, size=n_patients)\n",
    "weight = np.random.randint(50, 150, size=n_patients)  # in kilograms\n",
    "ventilator_duration = np.random.randint(0, 48, size=n_patients)  # hours on ventilator\n",
    "\n",
    "# Admission and follow-up variables\n",
    "icu_duration = np.random.randint(1, 20, size=n_patients)  # days in ICU\n",
    "death_within_year = np.random.choice([0, 1], size=n_patients, p=[0.9, 0.1])  # 10% mortality rate\n",
    "\n",
    "# Create a DataFrame\n",
    "data = pd.DataFrame({\n",
    "    'Gender': gender,\n",
    "    'Age': age,\n",
    "    'Diagnosis': diagnosis,\n",
    "    'Alcohol': alcohol,\n",
    "    'Smoking': smoking,\n",
    "    'Blood Pressure': blood_pressure,\n",
    "    'Mean Arterial Pressure': mean_arterial_pressure,\n",
    "    'Pulse': pulse,\n",
    "    'Oxygen Saturation': oxygen_saturation,\n",
    "    'Weight': weight,\n",
    "    'Ventilator Duration': ventilator_duration,\n",
    "    'ICU Duration': icu_duration,\n",
    "    'Death Within Year': death_within_year\n",
    "})\n",
    "\n",
    "data.head()\n",
    "```\n",
    "\n",
    "### Step 2: Perform Chi-Square Test\n",
    "\n",
    "To perform a chi-square test, we need to create a contingency table. Let’s test the association between two categorical variables, such as `Gender` and `Death Within Year`.\n",
    "\n",
    "```python\n",
    "# Create a contingency table\n",
    "contingency_table = pd.crosstab(data['Gender'], data['Death Within Year'])\n",
    "\n",
    "# Perform the chi-square test\n",
    "chi2, p, dof, ex = stats.chi2_contingency(contingency_table)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Chi-Square Statistic: {chi2}\")\n",
    "print(f\"P-Value: {p}\")\n",
    "print(f\"Degrees of Freedom: {dof}\")\n",
    "print(\"Expected Frequencies:\")\n",
    "print(ex)\n",
    "```\n",
    "\n",
    "### Step 3: Interpretation\n",
    "\n",
    "The chi-square statistic and p-value help us determine whether there is a significant association between the two categorical variables. A low p-value (typically ≤ 0.05) indicates that we can reject the null hypothesis, suggesting there is an association between the variables.\n",
    "\n",
    "### Full Example Code\n",
    "\n",
    "Here’s the complete example:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set a seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Generate synthetic data for 8000 patients\n",
    "n_patients = 8000\n",
    "\n",
    "# Profile variables\n",
    "gender = np.random.choice(['Male', 'Female'], size=n_patients)\n",
    "age = np.random.randint(18, 90, size=n_patients)\n",
    "diagnosis = np.random.choice(['Diagnosis A', 'Diagnosis B', 'Diagnosis C'], size=n_patients)\n",
    "alcohol = np.random.randint(0, 20, size=n_patients)  # drinks per week\n",
    "smoking = np.random.choice(['Non-smoker', 'Former smoker', 'Current smoker'], size=n_patients)\n",
    "\n",
    "# Measurements variables\n",
    "blood_pressure = np.random.randint(90, 180, size=n_patients)\n",
    "mean_arterial_pressure = np.random.randint(70, 110, size=n_patients)\n",
    "pulse = np.random.randint(50, 120, size=n_patients)\n",
    "oxygen_saturation = np.random.randint(85, 100, size=n_patients)\n",
    "weight = np.random.randint(50, 150, size=n_patients)  # in kilograms\n",
    "ventilator_duration = np.random.randint(0, 48, size=n_patients)  # hours on ventilator\n",
    "\n",
    "# Admission and follow-up variables\n",
    "icu_duration = np.random.randint(1, 20, size=n_patients)  # days in ICU\n",
    "death_within_year = np.random.choice([0, 1], size=n_patients, p=[0.9, 0.1])  # 10% mortality rate\n",
    "\n",
    "# Create a DataFrame\n",
    "data = pd.DataFrame({\n",
    "    'Gender': gender,\n",
    "    'Age': age,\n",
    "    'Diagnosis': diagnosis,\n",
    "    'Alcohol': alcohol,\n",
    "    'Smoking': smoking,\n",
    "    'Blood Pressure': blood_pressure,\n",
    "    'Mean Arterial Pressure': mean_arterial_pressure,\n",
    "    'Pulse': pulse,\n",
    "    'Oxygen Saturation': oxygen_saturation,\n",
    "    'Weight': weight,\n",
    "    'Ventilator Duration': ventilator_duration,\n",
    "    'ICU Duration': icu_duration,\n",
    "    'Death Within Year': death_within_year\n",
    "})\n",
    "\n",
    "# Create a contingency table\n",
    "contingency_table = pd.crosstab(data['Gender'], data['Death Within Year'])\n",
    "\n",
    "# Perform the chi-square test\n",
    "chi2, p, dof, ex = stats.chi2_contingency(contingency_table)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Chi-Square Statistic: {chi2}\")\n",
    "print(f\"P-Value: {p}\")\n",
    "print(f\"Degrees of Freedom: {dof}\")\n",
    "print(\"Expected Frequencies:\")\n",
    "print(ex)\n",
    "\n",
    "# Visualize the contingency table\n",
    "contingency_table.plot(kind='bar', stacked=True)\n",
    "plt.title('Death Within Year by Gender')\n",
    "plt.xlabel('Gender')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "This example generates synthetic data based on the data description provided, creates a contingency table for the chi-square test, performs the test, and visualizes the results. Adjust the variables and parameters as needed to fit your specific dataset and analysis requirements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervisor meeting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13/02/2024 (virtual)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Questions:\n",
    "- Da vi ikke er medicin studerende, hvordan ved vi hvad der er vigtigt?\n",
    "  - Hvilke metrics kan vi evaluere? \n",
    "\n",
    "- Hvordan finder vi balancen mellem hvor meget medicin' teori vi skal have med? - Hvornår får vi adgang til dataen\n",
    "\n",
    "- Vi husker at du nævnte, at datasættet er meget stort. Uden medicinsk baggrund, hvordan skal vi evaluerer hvilke features der er \"værd\" eller relevante at tage med for træning af modeller (hvis vi ikke kan træne på alle features)?\n",
    "\n",
    "  - Eller er det anbefalet at lave en form for feature selection eller statistiske analyse for at finde relevante features (analyse af correlation of påvirkninger)?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes from the meeting:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Morten Mørup står for al ML delen og Lars står for Data\n",
    "- Lars = Anastasi læge (Hjerte afdeling)\n",
    "- Samlet data over 5 årigeperiode\n",
    "  \n",
    "- Data:\n",
    "  - 8000 patient forløb\n",
    "  - Alder, køn, fejl inden hjerte opretation, data under operation\n",
    "    - data under operation er bla det de har samlte ind\n",
    "    - Hvad data ser vi kun på en gang i mellem\n",
    "    - Hvad data kigger vi mest på\n",
    "  - Hvordan går det for patienter\n",
    "    - er det her en risiko patient\n",
    "      - er det end er kan risikere at dø, eller at det går dårligt\n",
    "      - evt skal de ikke operaes, hvis de har risiko for at dø \n",
    "        - Det her kan vi da lave noget ML til. \n",
    "    - eller er det en lav risiko patient \n",
    "  - Gemmer hvert minut dataen\n",
    "  - Størrelse af datasættet\n",
    "    - representativ\n",
    "    - Nemt at håndtere\n",
    "  - Overskueligt data\n",
    "  - Tænk over anomyseringen\n",
    "    - Jurisk er anomyseringen ikke godt nok\n",
    "\n",
    "- Outcome:\n",
    "  - Hvor længe overlever de\n",
    "  - hvor meget medicin skal de have\n",
    "  - Hvor meget support har de brug for\n",
    "\n",
    "- Sampler sjældent\n",
    "  - medicin \n",
    "  - krugien \n",
    "\n",
    "- Sample hyppigt\n",
    "  - Fx EKG\n",
    "\n",
    "- Der er allerede lavet ML på dataen\n",
    "  \n",
    "- Ny og spændende og værdifuldt for dem\n",
    "  - Kan vi undervej lavet en eller anden modellering undervejs af data der akn fortælle os nogen om tidligt i opreationen om det kommer til at gå dårligt\n",
    "  - Data pejer på at patienten ender i dialyse\n",
    "  - Euroscore siger noget om overlevelse men ikke om hvor lang tid forløbet tager\n",
    "\n",
    "- Der laves en kontrak til \"ansættes\" på rigshospialet\n",
    "- Få en laptop, der kan tilgå dataen.\n",
    "  - Laptoppen har ingen GPU og kan kun kører det den kan\n",
    "  - Kan godt tage laptoppen med sig\n",
    "  - 1 laptop til hver gruppe\n",
    "\n",
    "- Det er brgrænset hvilke informations kilder der hentes. \n",
    "\n",
    "- Taler overlevelse\n",
    "  - fx 90 dage\n",
    "  - På et år er det deres samlde \n",
    "\n",
    "- Tid på intensiv og tid på hospitalet ikke på operations bordet\n",
    "  \n",
    "- Hvis ikke man tager død så\n",
    "  \n",
    "- Forskningsspørgsmål:\n",
    "  - i hvilken grad kan man få explatertbart, men samtidig forstå ... \n",
    "\n",
    "- Teams gruppe\n",
    "  - invitere vejleder med\n",
    "\n",
    "- Mail til Lars\n",
    "  - chaoqun.zheng@regionh.dk\n",
    "\n",
    "- Mail til Chao\n",
    "  - lars.groenlykke@regionh.dk\n",
    "\n",
    "- baseline model (euro score)\n",
    "  - samlede .. overlevede\n",
    "  - logistisk regression\n",
    "  - lave Euro score selv på data\n",
    "    - se hvordan den beregner\n",
    "    - se hvordan den laver logistisk regression\n",
    "\n",
    "- Forstå modellen, eller om det bare at preditere godt?\n",
    "  - Klinisk relevant del\n",
    "    - State på behandling eller gøre om, så \n",
    "      - kendes betydningen af enkelte kombonenter\n",
    "      - vil gerne kunne handle\n",
    "    - **Explanibilliy er vigtig**\n",
    "      - Højt sat,\n",
    "        - er der en biologisk plausibilitet\n",
    "        - hvad kan være problamatisk\n",
    "          - kan forbygge\n",
    "        - modeller hvor det er nemmere at forklare\n",
    "\n",
    "- Skal kende de enkelte datakilder og redegøre og hvor de kommer fra\n",
    "  - Vigtigt for at kunne lave modellerne korrekt\n",
    "  - Standard mål, der er velbeskrevet\n",
    "  - Det medicin vi sksl kunne vil fx være, blodtryksmedicin til at sænke blodtrykket\n",
    "\n",
    "- Lars og Chao kan hjælpe med:\n",
    "  - Hvornår er blodtrykket ligesom nonsens\n",
    "  - Er det her overhoved biologisk muligt\n",
    "  - Data afgrænsning (god kvalitet af dataen)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 21/02/2024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* data.gov\n",
    "* GMM af dataset for brug på vores egen computer\n",
    "* aflevering i denne uge/næste uge\n",
    "* align spørgsmål med hospitalet\n",
    "\n",
    "* Arbejdsspørgsmål\n",
    "    * 30/90 dages overlevelsesrate(vigtig)\n",
    "    * Bedre perfomance end tidligere model\n",
    "    * Hvor meget mere giver data under operationen?\n",
    "    * indlæggelsestid\n",
    "    * længde på operation\n",
    "    * cor mellem de forskellige target variables\n",
    "    * Hvad betyder det hvis patienter dør udner operationen\n",
    "    * Bliver de bedre til operationen over tid?\n",
    "    * 3 forskningsspørgsmål\n",
    "\n",
    "* Forskningsspørgsmål ka godt ændres hvis det er nødvendigt\n",
    "* Hvis vi ikke får bedre resultater end logistic regression er det ok, bare det er gjort rigtigt\n",
    "* Transformer Deep Learning\n",
    "* Opdeling i grupper af dataset\n",
    "* Samme perfomance metrics for alle models \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1/03/2024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Møde med Lars og Theis omkring computer og data\n",
    "\n",
    "* Alle i gruppen er til stede\n",
    "\n",
    "* **Noter omkring data:**\n",
    "    * Data fås i Excel format\n",
    "    * Måles i følgende \"attributes\":\n",
    "        * CPR, Alder på operationstidspunkt, Køn, Dødsdato, Død inden for 1 år af operationen, operationsdato, Operations SKS kode og operationsnavn \n",
    "    * Vi kigger på 8000 patierner, men der er målinger for op til 46000 patienter\n",
    "    * Hvis der er et eksempel men en værdi er 0 (som pulsen) men blodtryk og andre værdier ikke er 0, så er der sket en fejlmældning\n",
    "\n",
    "* Omkring operationens gennemgang:\n",
    "    * Stareter med induktion og går derefter til bypass indtil hjertet stopper, derfra kan man stage Aorta tangen af. Herefter stoppes bypass og data indsamling stoppes.\n",
    "\n",
    "* Fokuspunkter på forskningsspørgsmål:\n",
    "    * Gå efter target \"død\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 22/03/2024 (virtual)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Alle var tilstedeværende til mødet\n",
    "\n",
    "* Spørgsmål omkring computeren blev stillet, men løsning vedrørnde adgang til at pip installere pakker mangler stadig\n",
    "\n",
    "* Lars gennemgik diverse Excel data filer, herunder hvad de indeholdte og forklarede, at hver patient havde et \"falsk\" ID navn for notationens skyld (denne, for hver patient, er det samme gennem alle filerne)\n",
    "    * For eksempel viser et Excel dokument Alkohol og rygning forbundet med en vis usikkerhed (under samme filnavn)\n",
    "    * Enheden for målinger i Excel filen \"Advancerede hæmofynamiske mål\" er målt i mililiter kviksøl (står udmiddelbart ikke i selve filen)\n",
    "    * Problemlisten er en vigtig film som lister patienters sygdomme, som for eksempel at nogen har haft blodprop eller hjertestop før eller lider af sukkersyge\n",
    "\n",
    "Flere noter med hensyn til variable i diverse Excel filer:\n",
    "\n",
    "**Alkohol:**\n",
    "\n",
    "* Anæstasi er fra respirator \n",
    "\n",
    "* Blodtryk måles på 2 forskellige måder\n",
    "\n",
    "* Kateter i pulsåre i håndleddet og bånd i armen\n",
    "\n",
    "* Giver samme resultat, kater mere præcis \n",
    "\n",
    "* Puls og frem er fra monitor alt over er fra respirator\n",
    "\n",
    "**I cirk:**\n",
    "\n",
    "* Ting kan optræde flere fange alt efter hvor de henter data fra.\n",
    "Map tryk kan udregnes ud fra blodtrykket \n",
    "\n",
    "* Missing values fordi de ikke er gået i gang endnu \n",
    "\n",
    "* Nogen får målt tryk i længere ikke alle og derfor vil der være mange missing values\n",
    "Anæstasihændelse \n",
    "\n",
    "* Induktion er når patienten bliver bedøvet på stuen.\n",
    "Stop er når patient bliver kørt ud \n",
    "\n",
    "**Cv bypass:**\n",
    "\n",
    "* At klemme aorta af er en vigtig måling\n",
    "\n",
    "* Har betydning for hvordan de går dem.\n",
    "Blødning\n",
    "\n",
    "* Kan lave en summering af hvor meget de har blødt\n",
    "\n",
    "* Dialyse er ikke vigtig lige nu\n",
    "\n",
    "* Outcome i hvordan går det dem\n",
    "\n",
    "* Er de i dialyse eller ej\n",
    "\n",
    "**Ekko:**\n",
    "* Skannet deres hjerte med ultralyd \n",
    "\n",
    "* Nogen er ikke relevante og det finder chao, Theis og Lars ud af\n",
    "\n",
    "**Intellispace:**\n",
    "\n",
    "* Samme som ekko bare med meget mere data kan have noget der er målt to gange\n",
    "\n",
    "**Ita:** \n",
    "\n",
    "* Hvor længe er de på intensiv, ligegyldig om det er på riget eller Hvidovre\n",
    "\n",
    "**Kag:**\n",
    "\n",
    "* Undersøgelse af krans pulsåre \n",
    "\n",
    "* Mange patienter har fået lavet bypass.\n",
    "\n",
    "* Krans kan have været forsnævret ellers helt lukket af \n",
    "\n",
    "* Hvilke kar og hvor meget er de lukket af\n",
    "\n",
    "**Lab svar:**\n",
    "\n",
    "* Alle de blodprøver de får målt\n",
    "\n",
    "* Her skal alt ikke bruges \n",
    "\n",
    "* Men stiger nyretallet og stiger blodprocenten. \n",
    "\n",
    "* Får de infektioner\n",
    "\n",
    "**Dræn:**\n",
    "\n",
    "* Lunge og væskhule\n",
    "\n",
    "* Væske de taber\n",
    "\n",
    "* Ikke så mange af dem\n",
    "\n",
    "* Problemliste. \n",
    "\n",
    "* Hvor syge var de i forvejen? \n",
    "\n",
    "* Hvad fejlede de?\n",
    "\n",
    "* Har stor indflydelse på hvordan det går dem\n",
    "\n",
    "**Respirator:**\n",
    "\n",
    "* Indstillinger fra respirator\n",
    "\n",
    "* 2 forskellige maskiner så dataen kan godt være lidt forskellig\n",
    "\n",
    "* Hvis de stopper med at trække vejret, hvornår skal maskinen så gøre noget. Det er ikke vigtigt\n",
    "\n",
    "**Spir:**\n",
    "\n",
    "* Hvor lunge syge er de når de går til operation\n",
    "\n",
    "**Total:**\n",
    "\n",
    "* Hvad får de ind\n",
    "\n",
    "* Væske og medicin\n",
    "\n",
    "* Filtrere på tiden, så kan man se under operationen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spørgsmål til møde:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Må vi bruge plots det er lavet på det rigtige dataset, eller skal plots og perfomance også være fra et syntetisk dataset?  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feedback møde"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Onsdag den 3 april, blev der afholdt feedback møde angående det første \"færdige\" del af fagprojektet. \\\n",
    "Vi aftalte med den anden gruppe at mødes kl 14 i 324 på DTU. \n",
    "\n",
    "Inden mødes, mødtes vi alle 4 for at udarbejde et skriv til feedback gruppen, baseret på de 3 c'er og burger modellen. \n",
    "\n",
    "Vi alle 4 mødtes med feedbackgruppen. Mødte gik godt, de tog godt imod vores feedback og var alle aktiv lyttende. Der var dertil også samtale om nogen af kommentarerne, hvilket fungerede godt. \n",
    "\n",
    "Stemningen var god, og alle virkede glade. \n",
    "\n",
    "Feedback gruppen gav god feedback til vores opgave, og vi var alle dertil også aktiv lyttende. \n",
    "\n",
    "Der var dertil god samtale om ting i hinanden opgave, der var inspirerende, som hver gruppe ville tilføje til deres egen opgave. \n",
    "\n",
    "Mødet varede 45 minutter, og det blev aftalt at sende feedbacken på mail til hinanden. \n",
    "\n",
    "Efter mødet, blev Viktor, Lucia og Muneer og lige skrev det sidste få linjer på feedbacken så den kunne blive sendt afsted til den anden gruppe. Grundet til at de sidste linjer ikke blev gjort færdig, var at feedback gruppen, kom 10 min før aftalt tid. \n",
    "\n",
    "Det blev aftalt at Ditte skrev logbog, hvor de andre skrev det sidste. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Opdatering af projektplan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tirsdag den 1. maj gik vi i gang med at arbejde på den opdateret plan af projektet. Vi mødtes virtuelt og alle var til stede. Her lavede vi en Gantt chart, hvori vi lagde en plan for hvilke datoer vi ville arbejde med hvad og sat deadlines på de forskellige sections. Gantt charten hjalp os med at få et overblik over hvor lang tid vi skal bruge på de forskellige sectioner, og om det er feasible. Derudover har vi opdateret vores project canvas så det passer med alt vi har gennemarbejdet og alt vi har planlagt at lave. Sidst opdaterede vi vores projektbeskrivelse hvor der blev taget højde for den feedback vi fik fra vores peers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Møde med \"søster\" gruppe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10/06/24"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kl 12.00\n",
    "\n",
    "Alle i vores gruppe mødtes med søster gruppen for at spare ang. fagprojektet. \n",
    "Vi talte om hvordan data bliver sorteret samt det at lave syntetisk data eller ej. \n",
    "Dertil var vi inde på hvilke forskellige modeller vi hver især benytter, samt hvad vores fokus er / forskingsspørgsmål. \n",
    "Vi er blevet klogere på at vi ikke skal bruge mere fokus på at finde ud af at generere syntetisk data, da det kræver enormt meget. Dertil kan vi lave pyton fil, som kun indeholder kode, som bliver det der bliver oploadet til git, så dataen ikke kommer til git. \n",
    "\n",
    "Dertil er vi blevet klogere på at forstå daten, da vores søster gruppe har brugt meget tid på at forstå dataen. \n",
    "\n",
    "Ydermere, har vi talt om hvordan vi forholder os til EuroSCORE, og vi har måtte erkende at vi ikke kan holde vores modeller op til EuroSCORE, da vi ikke kan få EuroSCOREN på patienterne i dataen, og dertil har vi ikke de samme features i datasættet, som EuroSCOREN bygger på. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
