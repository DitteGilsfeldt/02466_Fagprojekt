{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_bool(size):\n",
    "    return np.random.rand(size) > 0.5\n",
    "\n",
    "def random_int(min, max, size):\n",
    "    return np.random.randint(min, max, size=size)\n",
    "\n",
    "def random_float(min, max, size):\n",
    "    return np.random.uniform(min, max, size=size)\n",
    "\n",
    "\n",
    "def index_id(max):\n",
    "    list = []\n",
    "    for i in range(1, max):\n",
    "        list.append('ID' + str(i))\n",
    "    return list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_op = pd.DataFrame({'IDno': index_id(501), 'Død inden for 1 år af operation': random_bool(500), 'age': random_int(18, 89, 500), 'sex': random_bool(500), 'Respiratory Disease': random_bool(500),\n",
    "       'Circulatory Organ Disease': random_bool(500), 'Type 1 Diabetes': random_bool(500), 'Type 2 Diabetes': random_bool(500),\n",
    "       'Other metabolic diseases': random_bool(500), 'Other operation': random_bool(500), 'Genital or urine related diseases': random_bool(500), 'Vægt': random_float(35, 190,500), 'KFN': random_bool(500), 'KFX': random_bool(500), 'KFK': random_bool(500), 'KFM': random_bool(500),\n",
    "       'KFF': random_bool(500), 'KFP': random_bool(500), 'KFC': random_bool(500), 'KFW': random_bool(500), 'KFJ': random_bool(500), 'Hæmoglobin': random_float(4,12,500), 'Leukocytter': random_float(1, 125, 500),\n",
    "       'Trombocytter': random_float(20, 1000, 500)})\n",
    "pre_op = pre_op.replace(True, 1).replace(False, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Mortality with pre_op data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split( pre_op.loc[:, pre_op.columns != 'Død inden for 1 år af operation'], pre_op['Død inden for 1 år af operation'], test_size=0.3, random_state=42)\n",
    "\n",
    "def lr_pred(X_train, y_train, X_test):\n",
    "    clf = LogisticRegression().fit(X_train, y_train)\n",
    "    return clf.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random forrest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient boost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score: 0.4734299516908213\n",
      "PR AUC Score: 0.4267304385325793\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import roc_auc_score, precision_recall_curve, auc\n",
    "\n",
    "\n",
    "def random_bool(size):\n",
    "    return np.random.rand(size) > 0.5\n",
    "\n",
    "def random_int(min, max, size):\n",
    "    return np.random.randint(min, max, size=size)\n",
    "\n",
    "def random_float(min, max, size):\n",
    "    return np.random.uniform(min, max, size=size)\n",
    "\n",
    "def index_id(max):\n",
    "    return ['ID' + str(i) for i in range(1, max)]\n",
    "\n",
    "pre_op = pd.DataFrame({\n",
    "    'IDno': index_id(501),\n",
    "    'Død inden for 1 år af operation': random_bool(500),\n",
    "    'age': random_int(18, 89, 500),\n",
    "    'sex': random_bool(500),\n",
    "    'Respiratory Disease': random_bool(500),\n",
    "    'Circulatory Organ Disease': random_bool(500),\n",
    "    'Type 1 Diabetes': random_bool(500),\n",
    "    'Type 2 Diabetes': random_bool(500),\n",
    "    'Other metabolic diseases': random_bool(500),\n",
    "    'Other operation': random_bool(500),\n",
    "    'Genital or urine related diseases': random_bool(500),\n",
    "    'Vægt': random_float(35, 190,500),\n",
    "    'KFN': random_bool(500),\n",
    "    'KFX': random_bool(500),\n",
    "    'KFK': random_bool(500),\n",
    "    'KFM': random_bool(500),\n",
    "    'KFF': random_bool(500),\n",
    "    'KFP': random_bool(500),\n",
    "    'KFC': random_bool(500),\n",
    "    'KFW': random_bool(500),\n",
    "    'KFJ': random_bool(500),\n",
    "    'Hæmoglobin': random_float(4,12,500),\n",
    "    'Leukocytter': random_float(1, 125, 500),\n",
    "    'Trombocytter': random_float(20, 1000, 500)\n",
    "})\n",
    "\n",
    "pre_op = pre_op.replace(True, 1).replace(False, 0)\n",
    "\n",
    "class GradientBoosting:\n",
    "    def __init__(self, balanced=False):\n",
    "        self.balanced = balanced\n",
    "        self.feature_importance = None\n",
    "        self.shap_values = None\n",
    "        self.num_trials = 0\n",
    "\n",
    "    def create_model(self, random_state):\n",
    "        seed_value = random_state.get_state()[1][0]\n",
    "        param = {\n",
    "            \"max_depth\": 2,\n",
    "            \"learning_rate\": 1,  # 'eta' is renamed to 'learning_rate' in XGBClassifier\n",
    "            \"reg_lambda\": 0.25,  # 'lambda' is renamed to 'reg_lambda' in XGBClassifier\n",
    "            \"subsample\": 0.5,\n",
    "            \"n_jobs\": 6,  # 'nthread' is renamed to 'n_jobs' in XGBClassifier\n",
    "            \"objective\": \"binary:logistic\",\n",
    "            \"random_state\": seed_value,\n",
    "        }\n",
    "        model = XGBClassifier(**param)\n",
    "        return {\n",
    "            \"model\": model,\n",
    "            \"param\": param,\n",
    "            \"num_round\": 10,  # Not used directly with XGBClassifier\n",
    "        }\n",
    "\n",
    "    def fit_model(self, model, train_data, train_labels):\n",
    "        model[\"model\"].fit(train_data, train_labels)\n",
    "\n",
    "    def predict_model(self, model, test_data):\n",
    "        preds = model[\"model\"].predict_proba(test_data)[:, 1]\n",
    "        return preds\n",
    "\n",
    "    @staticmethod\n",
    "    def save_model(model, path):\n",
    "        bst = model[\"model\"]\n",
    "        bst.save_model(path)\n",
    "\n",
    "# Drop the 'IDno' column from the dataset before splitting\n",
    "pre_op = pre_op.drop(columns=['IDno'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(pre_op.loc[:, pre_op.columns != 'Død inden for 1 år af operation'], pre_op['Død inden for 1 år af operation'], test_size=0.3, random_state=42)\n",
    "\n",
    "gb_model = GradientBoosting()\n",
    "model = gb_model.create_model(np.random.RandomState(42))\n",
    "\n",
    "gb_model.fit_model(model, X_train, y_train)\n",
    "\n",
    "prediction = gb_model.predict_model(model, X_test)\n",
    "\n",
    "# Get probability predictions\n",
    "prob_predictions = gb_model.predict_model(model, X_test)\n",
    "\n",
    "# Get binary predictions\n",
    "binary_predictions = (prob_predictions > 0.5).astype(int)\n",
    "\n",
    "# Calculate ROC AUC\n",
    "roc_auc = roc_auc_score(y_test, prob_predictions)\n",
    "print(\"ROC AUC Score:\", roc_auc)\n",
    "\n",
    "#Calculate PR AUC\n",
    "precision, recall, _ = precision_recall_curve(y_test, prob_predictions)\n",
    "pr_auc = auc(recall, precision)\n",
    "print(\"PR AUC Score:\", pr_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.92096414e-01 3.12697738e-02 1.16537304e-01 9.55109681e-01\n",
      " 5.48931985e-01 4.69406146e-01 5.29897849e-03 1.32789905e-01\n",
      " 2.06973872e-02 2.76404122e-02 3.12531150e-01 6.13207886e-01\n",
      " 4.30207174e-01 4.69406146e-01 5.24183843e-01 8.34579904e-01\n",
      " 2.90851368e-01 4.50383812e-01 3.12531150e-01 7.21054260e-01\n",
      " 3.73593595e-01 8.87907221e-01 2.46339809e-01 9.46731642e-01\n",
      " 1.92096414e-01 4.15213588e-02 6.07208919e-02 2.59034854e-01\n",
      " 9.00014501e-02 6.02071253e-01 2.64124153e-01 2.59034854e-01\n",
      " 7.96009215e-01 4.16343072e-01 8.20316879e-01 9.99665456e-01\n",
      " 7.57770038e-01 1.14387048e-01 4.69406146e-01 1.32789905e-01\n",
      " 7.96009215e-01 6.91869151e-01 1.32789905e-01 2.79277037e-01\n",
      " 9.88444774e-01 3.26554597e-01 8.99081283e-01 5.49772440e-01\n",
      " 2.83164873e-01 5.29362371e-01 4.69406146e-01 5.89078808e-01\n",
      " 1.15394182e-04 3.55583992e-01 1.25985527e-03 4.50383812e-01\n",
      " 9.93857201e-01 7.96009215e-01 6.43372802e-01 8.93665587e-01\n",
      " 9.12457565e-01 9.19046924e-01 7.35088835e-01 9.87957947e-02\n",
      " 6.74660954e-01 4.69406146e-01 4.69406146e-01 2.79277037e-01\n",
      " 3.97979640e-01 9.08045318e-01 1.52287049e-01 1.32789905e-01\n",
      " 6.52939727e-01 8.28585917e-01 2.64124153e-01 3.26253977e-02\n",
      " 1.19076570e-02 6.56373774e-01 1.54025584e-01 1.32789905e-01\n",
      " 4.69406146e-01 2.64124153e-01 2.89087239e-06 8.17724324e-01\n",
      " 9.08045318e-01 2.59034854e-01 8.28585917e-01 6.93390420e-01\n",
      " 4.55531257e-01 5.96445729e-01 4.97623997e-01 4.75973601e-01\n",
      " 9.12457565e-01 7.65980160e-01 7.83913688e-01 3.56602264e-02\n",
      " 9.91477993e-01 5.20007291e-01 1.19076570e-02 1.32789905e-01]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# Define the target and features\n",
    "target = 'Død inden for 1 år af operation'\n",
    "features = [col for col in pre_op.columns if col != target and col != 'IDno']\n",
    "\n",
    "X = pre_op[features]\n",
    "y = pre_op[target]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "class GradientBoosting:\n",
    "    def __init__(self, balanced=False):\n",
    "        self.balanced = balanced\n",
    "        self.model = None\n",
    "\n",
    "    def create_model(self, random_state):\n",
    "        params = {\n",
    "            \"max_depth\": 2,\n",
    "            \"learning_rate\": 1,\n",
    "            \"n_estimators\": 10,\n",
    "            \"subsample\": 0.5,\n",
    "            \"random_state\": random_state.get_state()[1][0],\n",
    "        }\n",
    "        if self.balanced:\n",
    "            params[\"scale_pos_weight\"] = \"balanced\"\n",
    "        self.model = GradientBoostingClassifier(**params)\n",
    "        return self.model\n",
    "\n",
    "    def fit_model(self, model, train_data, train_labels):\n",
    "        model.fit(train_data, train_labels)\n",
    "\n",
    "    def predict_model(self, model, test_data):\n",
    "        preds = model.predict_proba(test_data)[:, 1]\n",
    "        return preds\n",
    "\n",
    "    @staticmethod\n",
    "    def save_model(model, path):\n",
    "        import joblib\n",
    "        joblib.dump(model, path)\n",
    "\n",
    "# Initialize the model\n",
    "gb_model = GradientBoosting()\n",
    "\n",
    "# Create the model parameters\n",
    "model = gb_model.create_model(np.random.RandomState(42))\n",
    "\n",
    "# Train the model\n",
    "gb_model.fit_model(model, X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "predictions = gb_model.predict_model(model, X_test)\n",
    "\n",
    "# Convert probabilities to binary outcomes\n",
    "threshold = 0.5\n",
    "binary_predictions = (predictions >= threshold).astype(int)\n",
    "\n",
    "# Convert the probabilities to a numpy array and print it\n",
    "probabilities_array = np.array(predictions)\n",
    "print(probabilities_array)\n",
    "\n",
    "# Evaluate the binary predictions\n",
    "accuracy = accuracy_score(y_test, binary_predictions)\n",
    "conf_matrix = confusion_matrix(y_test, binary_predictions)\n",
    "class_report = classification_report(y_test, binary_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.58\n",
      "Confusion Matrix:\n",
      " [[30 14]\n",
      " [28 28]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.68      0.59        44\n",
      "           1       0.67      0.50      0.57        56\n",
      "\n",
      "    accuracy                           0.58       100\n",
      "   macro avg       0.59      0.59      0.58       100\n",
      "weighted avg       0.60      0.58      0.58       100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
    "print(\"Classification Report:\\n\", class_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grouped cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [400, 400, 500]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[212], line 13\u001b[0m\n\u001b[0;32m     10\u001b[0m X_outer_train, y_outer_train \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mloc[outer_train_idx], y\u001b[38;5;241m.\u001b[39mloc[outer_train_idx]\n\u001b[0;32m     11\u001b[0m X_outer_test, y_outer_test \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mloc[outer_test_idx], y\u001b[38;5;241m.\u001b[39mloc[outer_test_idx]\n\u001b[1;32m---> 13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m inner_train_idx, inner_test_idx \u001b[38;5;129;01min\u001b[39;00m inner_cv\u001b[38;5;241m.\u001b[39msplit(X_outer_train, y_outer_train, groups\u001b[38;5;241m=\u001b[39mpre_op[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIDno\u001b[39m\u001b[38;5;124m'\u001b[39m]):\n\u001b[0;32m     14\u001b[0m     X_inner_train, y_inner_train \u001b[38;5;241m=\u001b[39m X_outer_train\u001b[38;5;241m.\u001b[39mloc[inner_train_idx], y_outer_train\u001b[38;5;241m.\u001b[39mloc[inner_train_idx]\n\u001b[0;32m     15\u001b[0m     X_inner_test, y_inner_test \u001b[38;5;241m=\u001b[39m X_outer_train\u001b[38;5;241m.\u001b[39mloc[inner_test_idx], y_outer_train\u001b[38;5;241m.\u001b[39mloc[inner_test_idx]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\model_selection\\_split.py:367\u001b[0m, in \u001b[0;36m_BaseKFold.split\u001b[1;34m(self, X, y, groups)\u001b[0m\n\u001b[0;32m    343\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msplit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, groups\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    344\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Generate indices to split data into training and test set.\u001b[39;00m\n\u001b[0;32m    345\u001b[0m \n\u001b[0;32m    346\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    365\u001b[0m \u001b[38;5;124;03m        The testing set indices for that split.\u001b[39;00m\n\u001b[0;32m    366\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 367\u001b[0m     X, y, groups \u001b[38;5;241m=\u001b[39m \u001b[43mindexable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    368\u001b[0m     n_samples \u001b[38;5;241m=\u001b[39m _num_samples(X)\n\u001b[0;32m    369\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_splits \u001b[38;5;241m>\u001b[39m n_samples:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\utils\\validation.py:453\u001b[0m, in \u001b[0;36mindexable\u001b[1;34m(*iterables)\u001b[0m\n\u001b[0;32m    434\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Make arrays indexable for cross-validation.\u001b[39;00m\n\u001b[0;32m    435\u001b[0m \n\u001b[0;32m    436\u001b[0m \u001b[38;5;124;03mChecks consistent length, passes through None, and ensures that everything\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    449\u001b[0m \u001b[38;5;124;03m    sparse matrix, or dataframe) or `None`.\u001b[39;00m\n\u001b[0;32m    450\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    452\u001b[0m result \u001b[38;5;241m=\u001b[39m [_make_indexable(X) \u001b[38;5;28;01mfor\u001b[39;00m X \u001b[38;5;129;01min\u001b[39;00m iterables]\n\u001b[1;32m--> 453\u001b[0m \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    454\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\utils\\validation.py:407\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    405\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[0;32m    406\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 407\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    408\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    409\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[0;32m    410\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [400, 400, 500]"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GroupKFold\n",
    "\n",
    "X = pre_op.loc[:, pre_op.columns != 'Død inden for 1 år af operation']\n",
    "y = pre_op['Død inden for 1 år af operation']\n",
    "\n",
    "outer_cv = GroupKFold(n_splits = 5)\n",
    "inner_cv = GroupKFold(n_splits = 5)\n",
    "\n",
    "for outer_train_idx, outer_test_idx in outer_cv.split(X, y, groups = pre_op['IDno']):\n",
    "    X_outer_train, y_outer_train = X.loc[outer_train_idx], y.loc[outer_train_idx]\n",
    "    X_outer_test, y_outer_test = X.loc[outer_test_idx], y.loc[outer_test_idx]\n",
    "\n",
    "    for inner_train_idx, inner_test_idx in inner_cv.split(X_outer_train, y_outer_train, groups=pre_op['IDno']):\n",
    "        X_inner_train, y_inner_train = X_outer_train.loc[inner_train_idx], y_outer_train.loc[inner_train_idx]\n",
    "        X_inner_test, y_inner_test = X_outer_train.loc[inner_test_idx], y_outer_train.loc[inner_test_idx]\n",
    "\n",
    "        print('works')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
